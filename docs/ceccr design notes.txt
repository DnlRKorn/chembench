Cutoffs for modeling 
====================
AdminSettings

Predictor Types
===============
The predictors table cbench_predictor stores all of the predictive models seen
on the Predictors JSP page.
The field "type" in cbench_predictor controls the behavior of that page.
If the type is...
"Unsaved": The predictor is in the system, created by a modeling run, but 
will not be appear on the Predictors page until it has been selected from the Jobs page
and saved by the user.
"Private": When a model made by a user gets saved, it becomes Private. On the Predictors page,
a Private predictor will appear if the type is "Private" and the "username" field of 
cbench_predictor matches the login of the user.
"ADMETox": Predictors that have been manually added to the system and are available to everyone.
If the type is "ADMETox", it doesn't matter what the username is on it, everyone will see the predictor.
"DrugDiscovery": Just like ADMETox.

Starting the Server
===================
When Tomcat is restarted, the queue won't wake up right away; someone has to log in first.
Logging in wakes up the persistence code, creating an instance of 
edu.unc.ceccr.persistence.Queue, which in its constructor calls startRunning(). That
gets the queue thread going. 

The Queue
=========
Queue has a variable "runningTask" in it that tells you - shabam! - what task is running.
If you want to get access to that task from anywhere in the code, just grab the instance of
Queue (it's a singleton) and check its runningTask.

To implement canceling of running jobs:
All Task needs is a variable in it called "killed". 
Then you do this...
Organize the control structure of each Task in such a way that it has:
- Am I killed yet?
- Run the next function in edu.unc.ceccr.workflows that I need
- Am I killed yet?
- Run the next function in edu.unc.ceccr.workflows that I need
- And so on.
Getting this control structure in place will also be really nice for recovering
from failures. And for getting queue status updates handled in a sane way. Hmmmmmmm.

Each object in Workflows will need a variable "killed" as well. If the Workflows
function just does processing on its own, easy enough - just have it check if it's killed
yet as often as possible (within reason. Make it a for loop conditional or something.)
If it calls an external program using Process p = Runtime.exec(cmdstr), you need
to do something a touch trickier.
Usual way:
Process p = Runtime.exec(cmdstr)
p.waitFor()

New way:
Process p = Runtime.exec(cmdstr)
bool finished = false;
while(!killed && !finished){
  sleep(200)
  try{
    p.exitValue()
    finished = true;
  }
  catch(Exception ex){
    //don't do anything. p.exitValue() throws an
    //exception to indicate the process ain't done yet.
  }
}

Predictions
===========
To run a prediction job, we'll need a predictor and an SDF to make predictions on. 
If the predictor is one of the user's own predictors, the predictor is
copied in from username/modelbuilder/predictorname. If not, the predictor
is copied from all-users/predictor/predictorName.
If the SDF is uploaded, it will have landed in username/USERFILE, so we copy
it from there. If it was a selected dataset, we look for a file named
datasetname.sdf (The sdf is added on), and we look in all-users/sdf/DATATYPE/.

The dropdown for selectable SDFs on the Prediction page is reading off of the
database table cbench_db. Each entry in cbench_db has a corresponding entry in 
cbench_db_file. cbench_db_file should really be where the information's being 
read from... just needs to be fixed there first.